# Use a Triton-ready base image with Python and CUDA support
FROM nvcr.io/nvidia/tritonserver:24.10-py3-min

# Accept HF token as build argument
ARG HF_TOKEN
ENV HUGGING_FACE_HUB_TOKEN=$HF_TOKEN

# Install system dependencies required for audio processing libraries
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3-pip \
    libsndfile1 \
    && rm -rf /var/lib/apt/lists/*

# Set environment variables first
ENV PYTHONUNBUFFERED=0

# Copy only the requirements file first to leverage Docker layer caching
COPY requirements.txt .

# Install Python dependencies
# Use no cache for smaller image size
RUN pip install --no-cache-dir -r requirements.txt \
    && rm -rf ~/.cache/pip

# Copy downloaded models to /app (following the same pattern as audio)
COPY asr-rap/ /app/asr-rap/

# Set working directory for the application code
WORKDIR /home/app/src
COPY . .

# Configure Hugging Face cache location
ENV HF_HOME=/app/.cache/huggingface

EXPOSE 8017

# Update paths to match the directory structure in the downloaded models
ENTRYPOINT ["python3", "server_asr.py"]
CMD [ \
    "--gpu", \
    "--model-type=hybrid", \
    "--model-base-path=/app/asr-rap/whisper", \
    "--rap-model-path=/app/asr-rap/rap/model", \
    "--rap-vocab-path=/app/asr-rap/rap/vocab.json", \
    "--mms-base-path=/app/asr-rap/mms-1b-all" \
]
